{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('ResAss_w_PbSch_Rtngs_Clnd_df.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# month : The month as January=1, December=12\n",
    "df['Documentation_YearAge'] = 2017.0 - df['DocumentDate'].dt.year\n",
    "#df['Documentation_month'] = df['DocumentDate'].dt.month\n",
    "\n",
    "df.drop(['DocumentDate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def documentation_season(df):\n",
    "#    df['winter'] = (df['Documentation_month'].isin([1,2,12]).astype(int))\n",
    "#    df['spring'] = (df['Documentation_month'].isin([3,4,5]).astype(int))\n",
    "#    df['summer'] = (df['Documentation_month'].isin([6,7,8]).astype(int))\n",
    "#    df['fall'] = (df['Documentation_month'].isin([9,10,11]).astype(int))\n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = documentation_season(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.drop(['Documentation_month'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['fall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def Doc_month_converter(df):\n",
    "#    Doc_month_dummies = pd.get_dummies(df.Documentation_month, drop_first=False, prefix='DocMonth')\n",
    "#    df = pd.concat([df, Doc_month_dummies], axis=1).drop('Documentation_month', axis=1)\n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = Doc_month_converter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['TotalCost'] = df['SalePrice'] + df['AddnlCost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df) #, len(df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SaleWarning_conv(df):\n",
    "    df.SaleWarning = df.SaleWarning.apply(lambda x: x.split())\n",
    "    warningdummies = pd.get_dummies(df.SaleWarning.apply(pd.Series).stack(), prefix='SWarn', drop_first=False).sum(level=0)\n",
    "    df = df.join(warningdummies, how='left').fillna(0.0)\n",
    "    df = df.drop('SaleWarning', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = SaleWarning_conv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Zipcode_converter(df):\n",
    "    Zipcode_dummies = pd.get_dummies(df.Zipcode, drop_first=False)\n",
    "    df = pd.concat([df, Zipcode_dummies], axis=1).drop('Zipcode', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = Zipcode_converter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HeatSource_converter(df):\n",
    "    HeatSource_dummies = pd.get_dummies(df.HeatSource, drop_first=False, prefix='HeatSource')\n",
    "    df = pd.concat([df, HeatSource_dummies], axis=1).drop('HeatSource', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HeatSystem_converter(df):\n",
    "    HeatSystem_dummies = pd.get_dummies(df.HeatSystem, drop_first=False, prefix='HeatSystem')\n",
    "    df = pd.concat([df, HeatSystem_dummies], axis=1).drop('HeatSystem', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SqFTLiving_check(df):\n",
    "    df = df[df.SqFtTotLiving > 500]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NumLivingUnits_check(df):\n",
    "    df = df[df.NbrLivingUnits <= 2]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = HeatSource_converter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = HeatSystem_converter(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = SqFTLiving_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = NumLivingUnits_check(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['Address', 'StreetName', 'StreetType', 'SellerName', 'BuyerName', 'DirectionSuffix', \n",
    "         'parcel_number', 'PROP_NAME', 'ES_ZONE', 'MS_ZONE', 'HS_ZONE', 'LEVY_JURIS', 'SalePrice', \n",
    "         'AddnlCost', 'ExciseTaxNbr', 'BldgGrade', 'SaleReason', 'SaleInstrument', 'FinBasementGrade'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uplimit = min(df.TotalCost.mean() + df.TotalCost.std()*4, 2000000)\n",
    "bottomlimit = 100000 # min(abs(df.TotalCost.mean() - df.TotalCost.std()*4), df.TotalCost.min())\n",
    "print uplimit, bottomlimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[(df.TotalCost > bottomlimit) & (df.TotalCost < uplimit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalCost.max(), df.TotalCost.min(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalCost.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.TotalCostRed = df.TotalCost/10**5\n",
    "plt.hist(df.TotalCostRed, bins=50)\n",
    "plt.xlabel(\"Housing prices $ X 100K\")\n",
    "plt.ylabel(\"Number of Houses\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.TotalCost, bins=50)\n",
    "plt.xlabel(\"Housing prices $\")\n",
    "plt.ylabel(\"Number of Houses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log(df.TotalCost), bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = df.TotalCost\n",
    "X = df.drop('TotalCost', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSM1 = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=0)\n",
    "FSM1.fit(X_train, y_train)\n",
    "y_predict1 = FSM1.predict(X_test).astype(int)\n",
    "y_true = y_test.as_matrix()\n",
    "FSM1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = np.log(y_true) - np.log(y_predict1)\n",
    "plt.hist(residuals, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(y_true), residuals, alpha=0.15)\n",
    "plt.xlabel(\"log(y_true) 'Total Cost $ x 100K'\")\n",
    "plt.ylabel(\"log(y_true/y_predicted)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_absolute_error(y_true, y_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median_absolute_error(y_true, y_predict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict1 = FSM1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.abs((y_true-y_predict1)/y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.median(np.abs(1 - y_predict1/y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y.mean(), y.max(), y.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - np.mean(np.abs(y_predict1/y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.sqrt(mean_squared_error(y_true, y_predict1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_log = np.log(df.TotalCost)\n",
    "# X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X, y_log, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FSM2 = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=0)\n",
    "# FSM2.fit(X_train_log, y_train_log)\n",
    "# y_predict2 = FSM2.predict(X_test_log).astype(int)\n",
    "# y_true_log = y_test_log.as_matrix()\n",
    "# FSM2.score(X_test_log, y_test_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# residuals2 = y_true_log - y_predict2\n",
    "# plt.hist(residuals2, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# median_absolute_error(y_true_log, y_predict2), np.exp(median_absolute_error(y_true_log, y_predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print sum(abs(residuals))/len(y_predict1) # --> Winner is RF with subsected price range\n",
    "#print sum(abs(residuals2))/len(y_predict2)\n",
    "# print sum(abs(residuals3))/len(y_predict3)\n",
    "# print sum((residuals4))/len(y_predict4)\n",
    "#print abs(1 - np.exp(sum(abs(residuals))/len(y_predict1)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = FSM1.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in FSM1.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(28,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices],rotation='vertical')\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib.style('ggplot')\n",
    "importances = FSM1.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in FSM1.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(8,8))\n",
    "#plt.title(\"Feature importances\", fontsize=15)\n",
    "plt.bar(range(X.shape[1])[:10], importances[indices][:10],\n",
    "       color=\"r\", yerr=std[indices][:10], align=\"center\")\n",
    "plt.xticks(range(X.shape[1])[:10], X.columns[indices][:10],rotation='vertical', fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlim([-1, 10])\n",
    "#plt.gca().xaxis.label.set_fontsize(50)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['SWarn_13', 'HeatSystem_7', 'SWarn_16', 'SWarn_2','SWarn_56', 'HeatSystem_4', \n",
    "         'ACL_Y', 'HeatSystem_1', 'ACL_N', 'HP_NaN', 'AFL_N', 'HP_N', 'AFL_NaN', 'ACL_NaN', 'SWarn_8', 'SWarn_34', \n",
    "         'SWarn_11', 'SWarn_44', 'SWarn_40', 'HeatSystem_2', 'SWarn_41', 'SWarn_23', 'SWarn_60', 'SWarn_24',\n",
    "         'HeatSystem_8', 'HeatSource_5', 'SqFtUnfinHalf','HeatSource_7', 'SWarn_54', 'HeatSource_0','HeatSystem_0', \n",
    "         'SWarn_39', 'SWarn_38', 'SWarn_30', 'SWarn_36', 'SWarn_7', 'SqFtUnfinFull', 'SWarn_4', 'SWarn_55', 'SWarn_17','SWarn_3',\n",
    "         'HeatSource_6', 'SWarn_32','SWarn_20','SWarn_14','SWarn_37','SWarn_33','SWarn_21','HP_Y', 'SWarn_5','HeatSource_4',\n",
    "         'SWarn_35','SWarn_19', 'SWarn_28', 'SWarn_92', 'SWarn_*', 'SWarn_57', 'SWarn_50','SWarn_53','AFL_Y','SWarn_43',\n",
    "         'SWarn_43', 'SWarn_48', 'SWarn_6', 'SWarn_9'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop([98126,98107,98146,98178,98133,98104], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys = df.TotalCost\n",
    "Xs = df.drop('TotalCost', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs, ys, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSMs = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=0)\n",
    "FSMs.fit(Xs_train, ys_train)\n",
    "ys_predict = FSMs.predict(Xs_test).astype(int)\n",
    "ys_true = ys_test.as_matrix()\n",
    "FSMs.score(Xs_test, ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "residualss = np.log(ys_true) - np.log(ys_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(residualss, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(ys_true), residualss, alpha=0.15)\n",
    "plt.xlabel(\"log(y_true/y_predicted)\")\n",
    "plt.ylabel(\"log(y_true) 'Total Cost $ x 100K'\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ys_predict = FSMs.predict(Xs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.abs((ys_true-ys_predict)/ys_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-np.median(np.abs((ys_true-ys_predict)/ys_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = FSMs.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in FSMs.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(28,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(Xs.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(Xs.shape[1]), Xs.columns[indices],rotation='vertical')\n",
    "plt.xlim([-1, Xs.shape[1]])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n",
    "# FSMs = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=0)\n",
    "dt_range = range(1, 11)\n",
    "params = dict(max_depth=dt_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "\n",
    "    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n",
    "    score = 1-np.median(np.abs((y_true-y_predict)/y_true))\n",
    "\n",
    "    # Return the score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "# We initially created performance_metric using R2_score\n",
    "from sklearn.metrics import make_scorer\n",
    "scoring_fnc = make_scorer(performance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross-validation sets from the training data\n",
    "# ShuffleSplit works iteratively compared to KFOLD\n",
    "# It saves computation time when your dataset grows\n",
    "# X.shape[0] is the total number of elements\n",
    "# n_iter is the number of re-shuffling & splitting iterations.\n",
    "from sklearn.cross_validation import ShuffleSplit\n",
    "cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(regressor, params, cv=cv_sets, scoring=scoring_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GridBest = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=300, n_jobs=-1, oob_score=False, random_state=0,\n",
    "           verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GridBest.fit(X_train, y_train)\n",
    "y_predict = GridBest.predict(X_test).astype(int)\n",
    "y_true = y_test.as_matrix()\n",
    "GridBest.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = GridBest.predict(X_test)\n",
    "np.median(np.abs((y_true-y_predict)/y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.15, random_state = 0)\n",
    "rand = RandomizedSearchCV(regressor, params, cv=cv_sets, scoring=scoring_fnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rand = rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ElasticNetCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L1 = 0.1 \n",
    "\n",
    "Standard Scalar and use pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = ElasticNetCV(l1_ratio=0.1, cv=10, n_jobs=-1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test.as_matrix()\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = regr.predict(X_test)\n",
    "np.median(np.abs((y_true-y_predict)/y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = ElasticNetCV(l1_ratio=0.5, cv=10, n_jobs=-1, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "y_predict = regr.predict(X_test)\n",
    "y_true = y_test.as_matrix()\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.abs((y_true-y_predict)/y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Dependence Plots do not work anything else than gradient boosting resressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble.partial_dependence import plot_partial_dependence\n",
    "from sklearn.ensemble.partial_dependence import partial_dependence\n",
    "from __future__ import print_function\n",
    "print(__doc__)\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('GradientBoostGridSearchFittedModel.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.abs((y_true-predict)/y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = np.log(y_true) - np.log(predict)\n",
    "plt.scatter(np.log(y_true), residuals, alpha=0.15)\n",
    "plt.xlabel(\"log(y_true) 'Total Cost $ x 100K'\")\n",
    "plt.ylabel(\"log(y_true/y_predicted)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(28,8))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), X.columns[indices],rotation='vertical')\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(28,8))\n",
    "plt.title(\"Feature importances\", fontsize=24)\n",
    "plt.bar(range(X.shape[1])[:10], importances[indices][:10],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(X.shape[1])[:10], X.columns[indices][:10],rotation='vertical', fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.xlim([-1, 10])\n",
    "#plt.gca().xaxis.label.set_fontsize(50)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_prediction_matrix(df):\n",
    "    df['Documentation_YearAge'] = 0\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pre = new_prediction_matrix(X)\n",
    "X_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre = model.predict(X_pre).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Matrix = X_pre\n",
    "Matrix['TotalCost'] = y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Matrix.to_pickle('GB_Pickled_Matrix.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
    "             learning_rate=0.1, loss='ls', max_depth=10, max_features=None,\n",
    "             max_leaf_nodes=None, min_impurity_split=1e-07,\n",
    "             min_samples_leaf=1, min_samples_split=2,\n",
    "             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "             presort='auto', random_state=0, subsample=1.0, verbose=0,\n",
    "             warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_idxs(df, lst):\n",
    "    idx_lst = []\n",
    "    for name in lst:\n",
    "        idx = df.columns.get_loc(name)\n",
    "        idx_lst.append(idx)\n",
    "    return idx_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_idxs(X_train, ['Documentation_YearAge', 'SqFtTotLiving', 'HS_Ranking', 'ES_Ranking'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [47, 8, 46, 44, (46, 44)]\n",
    "names = list(X_train.columns.values)\n",
    "\n",
    "fig, axs = plot_partial_dependence(model_1, X_train, features, feature_names=names, n_jobs=-1, grid_resolution=50, figsize=(14, 6))\n",
    "\n",
    "fig.suptitle('Partial dependence of Housing Prices for Seattle City')\n",
    "fig.subplots_adjust(top=0.5)  # tight_layout causes overlap with suptitle\n",
    "\n",
    "#plt.subplots_adjust(top=0.9)  # tight_layout causes overlap with suptitle\n",
    "\n",
    "#fig = plt.figure()\n",
    "\n",
    "# target_feature = (46, 44)\n",
    "# pdp, axes = partial_dependence(model_1, target_feature,\n",
    "#                                X=X_train, grid_resolution=50)\n",
    "# XX, YY = np.meshgrid(axes[0], axes[1])\n",
    "# Z = pdp[0].reshape(list(map(np.size, axes))).T\n",
    "# ax = Axes3D(fig)\n",
    "# surf = ax.plot_surface(XX, YY, Z, rstride=1, cstride=1,\n",
    "#                        cmap=plt.cm.BuPu, edgecolor='k')\n",
    "# ax.set_xlabel(names[target_feature[0]])\n",
    "# ax.set_ylabel(names[target_feature[1]])\n",
    "# ax.set_zlabel('Partial dependence')\n",
    "#  pretty init view\n",
    "# ax.view_init(elev=22, azim=122)\n",
    "# plt.colorbar(surf)\n",
    "# plt.suptitle('Partial dependence of house value on\\n'\n",
    "#              'HS Rating and ES Rating')\n",
    "# plt.subplots_adjust(top=0.9)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "#fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [47, 8, 46, 44, (46, 44)]\n",
    "names = list(X_train.columns.values)\n",
    "\n",
    "fig, axs = plot_partial_dependence(model_1, X_train, features, feature_names=names, n_jobs=-1, grid_resolution=50)\n",
    "\n",
    "fig.suptitle('Partial dependence of Housing Prices for Seattle City')\n",
    "fig.subplots_adjust(top=0.5)  # tight_layout causes overlap with suptitle\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "target_feature = (46, 44)\n",
    "pdp, axes = partial_dependence(model_1, target_feature,\n",
    "                               X=X_train, grid_resolution=50)\n",
    "XX, YY = np.meshgrid(axes[0], axes[1])\n",
    "Z = pdp[0].reshape(list(map(np.size, axes))).T\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(XX, YY, Z, rstride=1, cstride=1,\n",
    "                       cmap=plt.cm.BuPu, edgecolor='k')\n",
    "ax.set_xlabel(names[target_feature[0]])\n",
    "ax.set_ylabel(names[target_feature[1]])\n",
    "ax.set_zlabel('\\n\\nPartial dependence')\n",
    "# pretty init view\n",
    "ax.view_init(elev=22, azim=122)\n",
    "plt.colorbar(surf)\n",
    "plt.suptitle('Partial dependence of house value on\\n'\n",
    "             'HS Rating and ES Rating')\n",
    "plt.subplots_adjust(top=0.9)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "#fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X['Documentation_YearAge'], y/100000, alpha=0.15)\n",
    "plt.xlabel(\"Documentation Age\")\n",
    "plt.ylabel(\"Total Cost $ x 100K\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X['SqFtTotLiving'], y/100000, alpha=0.15)\n",
    "plt.xlabel(\"SqFtTotLiving\")\n",
    "plt.ylabel(\"Total Cost $ x 100K\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(2017.0-X['YrBuilt'], y/100000, alpha=0.15)\n",
    "plt.xlabel(\"Building Age\")\n",
    "plt.ylabel(\"Total Cost $ x 100K\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(X['LOTSQFT']), y/100000, alpha=0.15)\n",
    "plt.xlabel(\"Logarithmic Lot SqFt\")\n",
    "plt.ylabel(\"Total Cost $ x 100K\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.log(X['SqFtFinBasement']), y/100000, alpha=0.15)\n",
    "plt.xlabel(\"Logarithmic SqFt Fin Basement\")\n",
    "plt.ylabel(\"Total Cost $ x 100K\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVR(kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm1_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = y_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.abs((y_true-svm1_predict)/y_true)) * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df)\n",
    "del(X_train)\n",
    "del(y_train)\n",
    "del(X_test)\n",
    "del(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
